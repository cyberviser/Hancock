# Fly.io deployment config for Hancock — CyberViser
# Deploy: fly launch --config fly.toml
# Docs:   https://fly.io/docs/

app = "hancock-cyberviser"
primary_region = "iad"   # US East — change to: lhr (London), fra (Frankfurt), etc.

[build]
  dockerfile = "Dockerfile"

[env]
  HANCOCK_PORT = "5000"
  HANCOCK_RATE_LIMIT = "60"

# Secrets (never commit these — set via CLI):
#   fly secrets set HANCOCK_API_KEY=$(python -c "import secrets; print(secrets.token_urlsafe(32))")
#   fly secrets set OPENAI_API_KEY=sk-...        # for cloud deployments (HANCOCK_LLM_BACKEND=openai)
#   fly secrets set HANCOCK_LLM_BACKEND=openai  # Fly.io has no local Ollama; use OpenAI

[http_service]
  internal_port = 5000
  force_https = true
  auto_stop_machines = true    # Scales to zero when idle (saves free quota)
  auto_start_machines = true
  min_machines_running = 0

  [http_service.concurrency]
    type = "requests"
    hard_limit = 25
    soft_limit = 20

[[vm]]
  memory = "512mb"             # Free tier: 256MB RAM shared — bump if needed
  cpu_kind = "shared"
  cpus = 1

[checks]
  [checks.health]
    grace_period = "10s"
    interval = "30s"
    method = "GET"
    path = "/health"
    port = 5000
    timeout = "10s"
    type = "http"
